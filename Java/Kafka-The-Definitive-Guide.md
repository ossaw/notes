# Kafka权威指南读书笔记

## 第6章 可靠的数据传递

### 6.1 可靠性保证

1. Kafka可以保证分区消息的顺序。如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入，那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B。
2. 只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘），它才被认为是“已提交”的。生产者可以选择接收不同类型的确认（request.required.acks），比如在消息被完全提交时的确认，或者在消息被写入首领副本时的确认，或者在消息被发送到网络时的确认。
3. 只要还有一个副本是活跃的，那么已经提交的消息就不会丢失。
4. 消费者只能读取已经提交的消息。

### 6.2 复制
Kafka的复制机制和分区的多副本架构是Kafka可靠性保证的核心。把一个消息写入多个副本可以使Kafka在发生崩愤时仍能保证消息的持久性。

Kafka的主题被分为多个分区，分区是基本的数据块。分区存储在单个磁盘上，分区可以在线（可用），也可以离线（不可用）。每个分区可以有多个副本，其中一个副本是首领。所有的事件都直接发送给首领副本，或者直接从首领副本读取事件。其他副本只需要与首领保持同步，并及时复制最新的事件。当首领副本不可用时，其中一个同步副本将成为新首领。分区首领是同步副本，而对于跟随者副本来说，它需要满足以下条件才能被认为是同步的。

1. 与Zookeeper之间有一个活跃的会话，也就是说，它在过去的“（可配置）内向Zookeeper发送过心跳。
2. 在过去的10s内（可配置）从首领那里获取过消息。
3. 在过去的10s内从首领那里获取过最新的消息。光从首领那里获取消息是不够的，它还必须是几乎零延迟的。

如果跟随者副本不能满足以上任何一点，比如与Zookeeper断开连接，或者不再获取新消息，或者获取消息滞后了10s以上，那么它就被认为是不同步的。一个不同步的副本通过与Zookeeper重新建立连接，井从首领那里获取最新消息，可以重新变成同步的。这个过程在网络出现临时问题井很快得到修复的情况下会很快完成，但如果broker发生崩愤就需要较长的时间。

如果一个或多个副本在同步和非同步状态之间快速切换，说明集群内部出现了问题，通常是Java不恰当的垃圾回收配置导致的。不恰当的垃圾回收配置会造成几秒钟的停顿，从而让broker与Zookeeper之间断开连接，最后变成不同步的，进而发生状态切换。

更少的同步副本意味着更低的有效复制系数，在发生岩机时丢失数据的风险更大。

### 6.3 broker配置

> broker有3个配置参数会影响Kafka消息存储的可靠性。与其他配置参数一样，它们可以应用在broker级别，用于控制所有主题的行为，也可以应用在主题级别，用于控制个别主题的行为。

#### 6.3.1 复制系数

* 主题级别的配置参数是replicatlon.factor，而在broker级别则可以通过default.replication.factor来配置自动创建的主题。

* 主题创建之后，也可以通过新增或移除副本来改变复制系数。

* 如果复制系数为N，那么在N-l个broker失效的情况下，仍然能够从主题读取数据或向主题写入数据。所以更高的复制系数会带来更高的可用性、可靠性和更少的故障。另一方面，复制系数N需要至少N个broker，而且会有N个数据副本，也就是说它们会占用N倍的磁盘空间。

* 建议把broker分布在多个不同的机架上，并使用broker.rack参数来为每个broker配置所在机架的名字。如果配置了机架名字，Kafka会保证分区的副本被分布在多个机架上，从而获得更高的可用性。

#### 6.3.2 不完全的首领选举

* unclean.leader.election.enable只能在broker级别（实际上是在集群范围内）进行配置，它的默认值是true。

> 首领不可用时其他副本都是不同步的，这种情况会在以下两种场景里出现。

>> 1. 分区有3个副本，其中的两个跟随者副本不可用（比如有两个broker发生崩愤）。如果生产者继续往首领写入数据，所有消息都会得到确认井被提交（因为此时首领是唯一的同步副本）。现在我们假设首领也不可用了（又一个broker发生崩愤），这个时候，如果之前的一个跟随者重新启动，它就成为了分区的唯一不同步副本。
>> 2. 分区有3个副本，因为网络问题导致两个跟随者副本复制消息滞后，所以尽管它们还在复制消息，但已经不同步了。首领作为唯一的同步副本继续接收消息。这个时候，如果首领变为不可用，另外两个副本就再也无法变成同步的了。

> 对于这两种场景，我们要作出一个两难的选择。
>> 1. 如果不同步的副本不能被提升为新首领，那么分区在旧首领（最后一个同步副本）恢复之前是不可用的。有时候这种状态会持续数小时（比如更换内存芯片）。
>> 2. 如果不同步的副本可以被提升为新首领，那么在这个副本变为不同步之后写入旧首领的消息、会全部丢失，导致数据不一致。为什么会这样呢？假设在副本0和副本l不可用时，偏移量100-200的消息被写入副本2（首领）。现在副本2变为不可用的，而副本0变为可用的。副本0只包含偏移量O～100的消息，不包含偏移量100～200的消息。如果我们允许副本0成为新首领，生产者就可以继续写入数据，消费者可以继续读取数据。于是，新首领就有了偏移量100～200的新消息。这样，部分消费者会读取到偏移量100～200的旧消息，部分消费者会读取到偏移量100～200的新消息，还有部分消费者读取的是二者的混合。这样会导致非常不好的结果，比如生成不准确的报表。另外，副本2可能会重新变为可用，并成为新首领的跟随者。这个时候，它会把比当前首领旧的消息全部删除，而这些消息对于所有消费者来说都是不可用的。

unclean.leader.election.enable设为true，就是允许不同步的副本成为首领（也就是“不完全的选举”），那么我们将面临丢失消息的风险。如果把这个参数设为false,就要等待原先的首领重新上线，从而降低了可用性。

### 6.4 在可靠的系统中使用生产者

> 即使我们尽可能把broker配置得很可靠，但如果没有对生产者进行可靠性方面的配置，整个系统仍然有可能出现突发性的数据丢失。请看以下两个例子。

1. 为broker配置了3个副本，井且禁用了不完全首领选举，这样应该可以保证万无一失。我们把生产者发送消息的acks设为1（只要首领接收到消息就可以认为消息写入成功）。生产者发送一个消息给首领，首领成功写入，但跟随者副本还没有接收到这个消息。首领向生产者发送了一个响应，告诉它“消息写入成功”，然后它崩溃了，而此时消息还没有被其他副本复制过去。另外两个副本此时仍然被认为是同步的（毕竟判定一个副本不同步需要一小段时间），而且其中的一个副本成了新的首领。因为消息还没有被写入这个副本，所以就丢失了，但发送消息的客户端却认为消息已成功写入。因为消费者看不到丢失的消息，所以此时的系统仍然是一致的（因为副本没有收到这个消息，所以消息不算已提交），但从生产者角度来看，它丢失了一个消息。
2. 为broker配置了3个副本，并且禁用了不完全首领选举。我们接受了之前的教训，把生产者的acks设为all。假设现在往Kafka发送消息，分区的首领刚好崩愤，新的首领正在选举当中，Kafka会向生产者返回“首领不可用”的响应。在这个时候，如果生产者没能正确处理这个错误，也没有重试发送消息直到发送成功，那么消息也有可能丢失。这算不上是broker的可靠性问题，因为broker并没有收到这个消息。这也不是一致性问题，因为消费者井没有读到这个消息。问题在于如果生产者没能正确处理这些错误，弄丢消息的是它们自己。

> 从上面两个例子可以看出，每个使用Kafka的开发人员都要注意两件事情。

1. 根据可靠性需求配置恰当的acks值。
2. 在参数配置和代码里正确处理错误。

#### 6.4.1 发送确认

> 生产者可以选择以下3种不同的确认模式。

1. acks=0意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入Kafka。这种模式一定会丢失消息。

2. acks=1意味若首领在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应。在这个模式下，如果发生正常的首领选举，生产者会在选举时收到一个LeaderNotAvailableException异常，如果生产者能恰当地处理这个错误（参考6.4.2节），它会重试发送消息，最终消息会安全到达新的首领那里。不过在这个模式下仍然有可能丢失数据，比如消息已经成功写入首领，但在消息被复制到跟随者副本之前首领发生崩愤。

3. acks=all意味着首领在返回确认或错误响应之前，会等待所有同步副本都收到消息。如果和min.insync.replicas参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到消息。这是最保险的做法，生产者会一直重试直到消息被成功提交。不过这也是最慢的做法，生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。可以通过使用异步模式和更大的批次来加快速度，但这样做通常会降低吞吐量。

#### 6.4.2 配置生产者的重试次数

> 生产者需要处理的错误包括两部分：一部分是生产者可以自动处理的错误（如：LEADER_NOT_AVAILABLE），还有一部分是需要开发者手动处理的错误(如：INVALID_CONFIG)。

#### 6.4.3 额外的错误处理

使用生产者内置的重试机制可以在不造成消息丢失的情况下轻松地处理大部分错误，不过对于开发人员来说，仍然需要处理其他类型的错误，包括：

1. 不可重试的broker错误，例如消息大小错误、认证错误等
2. 在消息发送之前发生的错误，例如序列化错误
3. 在生产者达到重试次数上限时或者在消息占用的内存达到上限时发生的错误。我们在第3章讨论了如何为同步发送消息和异步发送消息编写错误处理器。

这些错误处理器的代码逻辑与具体的应用程序及其目标有关。丢弃“不合理的消息”？把错误记录下来？把这些消息保存在本地磁盘上？回调另一个应用程序？具体使用哪一种逻辑要根据具体的架构来决定。
如果错误处理只是为了重试发送消息，那么最好还是使用生产者内置的重试机制。

### 6.5 在可靠系统中使用消费者

已提交偏移量是消费者可靠消费的重中之重。

此处的己提交消息与之前讨论过的已提交消息是不一样的，它是指已经被写入所有同步副本并且对消费者可见的消息，而己提交偏移量是指消费者发送给Kafka的偏移量，用于确认它已经收到并处理好的消息位置。

#### 6.5.1 消费者的可靠性配置

> 为了保证消费者行为的可靠性，需要注意以下4个非常重要的配置参数。

1. group.id. 多个消费者消费同一主题下不同的group.id的消息互不干扰。

2. auto.offset.reset. 这个参数指定了在没有偏移量可提交时（比如消费者第l次启动时）或者请求的偏移量在broker上不存在时（第4章已经解释过这种场景），消费者会做些什么。这个参数有两种配置。一种是earliest，如果选择了这种配置，消费者会从分区的开始位置读取数据，不管偏移量是否有效，这样会导致消费者读取大量的重复数据，但可以保证最少的数据丢失。一种是latest，如果选择了这种配置，消费者会从分区的末尾开始读取数据，这样可以减少重复处理消息，但很有可能会错过一些消息。

3. enable.auto.commit. 是一个非常重要的配置参数，你可以让消费者基于任务调度自动提交偏移量，也可以在代码里手动提交偏移量。自动提交的一个最大好处是，在实现消费者逻辑时可以少考虑一些问题。如果你在消费者轮询操作里处理所有的数据，那么自动提交可以保证只提交已经处理过的偏移量（如果忘了消费者轮询是什么，请回顾一下第4章的内容）。自动提交的主要缺点是，无法控制重复处理消息（比如消费者在自动提交偏移量之前停止处理消息），而且如果把消息交给另外一个后台线程去处理，自动提交机制可能会在消息还没有处理完毕就提交偏移量。

4. auto.commit.interval.ms. 与第3个参数有直接的联系。如果选择了自动提交偏移量，可以通过该参数配置提交的频度，默认值是每5秒钟提交一次。一般来说，频繁提交会增加额外的开销，但也会降低重复处理消息的概率。

#### 6.5.2 显示提交偏移量

1. 总是在处理完事件后再提交偏移量。如果所有的处理都是在轮询里完成，并且不需要在轮询之间维护状态（比如为了实现聚合操作），那么可以使用自动提交，或者在轮询结束时进行手动提交。

2. 提交频度是性能和重复消息数量之间的权衡。即使是在最简单的场景里，比如所有的处理都在轮询里完成，并且不需要在轮询之间维护状态，你仍然可以在一个循环里多次提交偏移量（甚至可以在每处理完一个事件之后），或者多个循环里只提交一次（与生产者的acks=all配置有点类似），这完全取决于你在性能和重复处理消息之间作出的权衡。

3. 确保对提交的偏移量心里有数

4. 再均衡。在设计应用程序时要注意处理消费者的再均衡问题。我们在第4章举了几个例子，般要在分区被撤销之前提交偏移量，并在分配到新分区时清理之前的状态。

5. 消费者可能需要重试时候。在进行轮询之后，有些消息不会被完全处理，你想稍后再来处理。例如，假设要把Kafka的数据写到数据库里，不过那个时候数据库不可用，于是你想稍后重试。要注意，你提交的是偏移量，而不是对消息的“确认”，这个与传统的发布和订阅消息系统不太一样。如果记录的30处理失败，但记录的31处理成功，那么你不应该提交31，否则会导致的3l以内的偏移量都被提交，包括30在内，而这可能不是你想看到的结果。不过可以采用以下两种模式来解决这个问题。第一种模式，在遇到可重试错误时，提交最后一个处理成功的偏移量，然后把还没有处理好的消息保存到缓冲区里（这样下一个轮询就不会把它们覆盖掉），调用消费者的pause()方法来确保其他的轮询不会返回数据（不需要担心在重试时缓冲区隘出），在保持轮询的同时尝试重新处理（关于为什么不能停止轮询，请参考第4章）。如果重试成功，或者重试次数达到上限井决定放弃，那么把错误记录下来井丢弃消息，然后调用resul'le（）方能让消费者继续从轮询里获取新数据。第二种模式，在遇到可重试错误时，把错误写入一个独立的主题，然后继续。一个独立的消费者群组负责从该主题上读取错误消息，并进行重试或者使用其中的一个消费者同时从该主题上读取错误消息并进行重试，不过在重试时需要暂停该主题。这种模式有点像其他消息系统里的dead-letter-queue。

6. 消费者可能需要维护状态。有时候你希望在多个轮询之间维护状态，例如，你想计算消息的移动平均数，希望在首次轮询之后计算平均数，然后在后续的轮询中更新这个结果。如果进程重启，你不仅需要从上一个偏移量开始处理数据，还要恢复移动平均数。有一种办法是在提交偏移量的同时把最近计算的平均数写到一个“结果”主题上。消费者线程在重新启动之后，它就可以拿到最近的平均数并接着计算。不过这并不能完全地解决问题，因为Kafka并没有提供事务支持。消费者有可能在写入平均数之后来不及提交偏移量就崩溃了，或者反过来也一样。这是一个很复杂的问题，你不应该尝试自己去解决这个问题，建议尝试一下Kafk:aStreams这个类库，它为聚合、连接、时间窗和其他复杂的分析提供了高级的DSL API。

7. 长时间处理。有时候处理数据需要很长时间：你可能会从发生阻塞的外部系统获取信息，或者把数据写到外部系统，或者进行一个非常复杂的计算。要记住，暂停轮询的时间不能超过几秒钟。即使不想获取更多的数据，也要保持轮询，这样客户端才能往broker发送心跳。在这种情况下，一种常见的做法是使用一个线程地来处理数据，因为使用多个线程可以进行并行处理，从而加快处理速度。在把数据移交给线程地去处理之后，你就可以暂停消费者，然后保持轮询，但不获取新数据，直到工作线程处理完成。在工作线程处理完成之后，可以让消费者继续获取新数据。因为消费者一直保持轮询，心跳会正常发送，就不会发生再均衡。

8. 仅一次传递。有些应用程序不仅仅需要“至少一次”（at-least-once）语义（意味着没有数据丢失），还需要“仅一次”（exactly-once）语义。尽管Kafka现在还不能完全支持仅一次语义，消费者还是有一些办法可保证Kafka里的每个消息只被写到外部系统一次（但不会处理向Kafka写入数据时可能出现的重复数据）。实现仅一次处理最简单且最常用的办能是把结果写到一个支持唯一键的系统里，比如键值存储引擎、关系型数据库、ElasticSearch或其他数据存储引擎。在这种情况下，要么消息本身包含一个唯一键（通常都是这样），要么使用主题、分区和偏移量的组合来创建唯一键一一－它们的组合可以唯一标识一个Kafka记录。如果你把消息和一个唯一键写入系统，然后碰巧又读到一个相同的消息，只要把原先的键值覆盖掉即可。数据存储引擎会覆盖已经存在的键值对，就像没有出现过重复数据一样。这个模式被叫作事等性写入，它是一种很常见也很有用的模式。如果写入消息的系统支持事务，那么就可以使用另一种方法。最简单的是使用关系型数据库，不过HDFS里有一些被重新定义过的原子操作也经常用来达到相同的目的。我们把消息和偏移量放在同一个事务里，这样它们就能保持同步。在消费者启动时，它会获取最近处理过的消息偏移量，然后调用seek（）方也从该偏移量位置继续读取数据。我们在第4章已经介绍了一个相关的例子。

### 6.6 验证系统可靠性

略

### 6.7 总结

> 可靠性并不只是Kafka单方面的事情。我们应该从整个系统层面来考虑可靠性问题，包括应用程序的架构、生产者和消费者API的使用方式、生产者和消费者的配置、主题的配置以及broker的配置。系统的可靠性需要在许多方面作出权衡，比如复杂性、性能、可用性和磁盘空间的使用。掌握Kafka的各种配置和常用模式，对使用场景的需求做到心中有数，你就可以在应用程序和Kafka的可靠性程度以及各种权衡之间作出更好的选择。
