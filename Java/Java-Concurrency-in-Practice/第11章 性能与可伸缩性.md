## 第11章 性能与可伸缩性

### 11.1 对性能的思考

引入多线程会增加以下开销: 

* 线程之间协调(加锁, 触发信号, 内存同步等).
 
* 线程的上下文切换.

* 线程的创建和销毁.

* 线程的调度.

如果过度地使用线程, 那么这些开销甚至会超过提高吞吐量, 响应性, 计算能力锁带来的性能提升.

一个并发设计糟糕的程序, 其性能比实现相同功能的串行程序的性能还要差.

通过并发来获得更好的性能, 需要努力做好两件事:
 
* 更有效的利用现有处理资源.

* 在出现新的处理资源时使程序尽可能地利用这些新资源(程序伸缩性).

#### 11.1.1 性能和可伸缩性

1. 可伸缩性指的是: 当增加计算资源时(例如CPU, 内存, 存储容量或I/O带宽), 程序的吞吐量或者处理能力能相应地增加.

2. 性能的两个方面: **多快**和**多少**是完全独立的, 有时候甚至是相互矛盾的.

多快指的是性能调优: 用更小的代价完成相同的工作.

多少指的是可伸缩性, 吞吐量: 用更多的资源来完成更多的工作.

#### 11.1.2 评估各种性能权衡因素

1. 避免不成熟的优化. 首先使程序正确, 然后在提高运行速度----如果它还运行得不够快.

在使某个方案比其他方案更快之前, 首先问自己一些问题:

* 更快的含义是什么?
* 该方法在什么条件下运行的更快? 在低负载还是高负载的情况下? 大数据集还是小数据集? 能否通过测试结果来验证你的答案?
* 这些条件在运行环境中的发生频率? 能否通过测试结果来验证你的答案?
* 在其它不同条件的环境中能否使用这些代码?
* 在实现这种性能提升时需要付出哪些隐含的代价, 例如增加开发风险或维护开销? 这种权衡是否合适?

对性能的提升可能是并发错误的最大来源.

**以测试为基准, 不要猜测.**

### 11.2 Amdahl定律

1. 在增加计算资源的情况下, 程序在理论上能够实现最高加速比, 这个值取决于程序中并行组件与串行组件所占的比重. 假定F是必须被串行执行的部分, 那么根据Amdahl定律, 在包含N个处理器的机器中, 最高的加速比:

![11-1](https://github.com/ossaw/notes/blob/master/Pictures/jcip/java-concurrency-in-practice-11-1.jpg)

2. 在所有并发程序中都包含一些串行部分. 如果你认为在你的程序中不存在串行部分, 那么可以在检查一遍.

### 11.2.1 示例: 在各种框架中隐藏的串行部分

1. 要想知道串行部分是如何隐藏在应用程序的架构中, 可以比较线程增加时吞吐量的变化, 根据观察到的可伸缩性变化来推断串行部分中的差异.

#### 11.2.2 Amdahl定律的应用

锁分解技术: 将一个锁分解为两个锁.

锁分段技术: 将一个锁分解为多个锁.

### 11.3 线程引入的开销

对于提升性能而引入的线程来说, 并行带来的性能提升必须超过并发导致的开销.

#### 11.3.1 上下文切换

1. 如果可运行的线程数大于CPU的数量, 那么操作系统最终会将某个正在运行的线程调度出来, 从而使其它线程能够使用CPU, 这将导致一次上下文切换, 这个过程将保存当前线程的上下文, 并将新调度进来的线程执行上下文设置为当前上下文.

上下文切换开销如下:
* 分摊CPU资源: 线程上下文切换需要操作系统和JVM介入, 它们会分摊CPU资源.
* 缓存缺失: 新调度进来的线程需要的数据不在本地缓存中.

2. 线程阻塞(竞争锁, 线程等待, IO阻塞)会导致上下文切换, 无阻塞算法有助于线程上下文切换.

#### 11.3.2 内存同步

1. 不要过度担心非竞争同步带来的开销, 这个基本的机制已经非常快了, 并且JVM能够进行额外的优化以进一步降低或消除开销. 因此, 我们应该将重点放在那些发生锁竞争的地方.

#### 11.3.3 阻塞

1. 阻塞时间过短, 适合使用线程自旋等待方式, 阻塞时间过长, 适合使用线程挂起方式, 这由JVM分析历史等待时间来选择.

2. 被阻塞的线程在其执行时间片未被用完之前就被交换出去, 而在随后当要获取的锁或者资源可用时, 又再次被切换回来.

3. 由于锁竞争而导致阻塞时, 线程在持有锁时将存在一定的开销, 当它释放锁时, 必须告诉操作系统恢复运行阻塞的线程.

